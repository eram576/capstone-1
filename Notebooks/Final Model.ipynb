{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import heapq\n",
    "import spacy\n",
    "\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix,  classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Portal import *\n",
    "# pd.set_option('display.width', 400)\n",
    "# pd.set_option('display.max_columns', 10)\n",
    "\n",
    "\n",
    "class CareersFuture(Portal):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def read_data(self):\n",
    "        # Reads data\n",
    "        df = pd.read_csv('mycareerfuture2020-09-15.csv', error_bad_lines=False)\n",
    "        return df\n",
    "\n",
    "    def clean_data(self):\n",
    "        df = self.read_data()\n",
    "        # df = df[df['Job Description'].str.contains('value')]\n",
    "        df['Job Description'] = df['Job Description'].astype(str)\n",
    "        df['Job Description'] = df['Job Description'].apply(lambda x: self.strip_html_tags(x))\n",
    "\n",
    "        df['Industry'] = df['Industry'].astype(str)\n",
    "        df['Industry'] = df['Industry'].apply(lambda x: self.str_to_literal(x))\n",
    "\n",
    "        # df['Skills'] = df['Skills'].astype(str)\n",
    "\n",
    "        df['Job Experience Required (years)'] = df['Job Experience Required (years)'].astype(int)\n",
    "\n",
    "        df['Job Monthly Min Sal'] = df['Job Monthly Min Sal'].astype(int)\n",
    "        df['Job Monthly Max Sal'] = df['Job Monthly Max Sal'].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def str_to_literal(self, text):\n",
    "        try:\n",
    "            # ast.literal_eval function converts takes in a string and converts it into a dictionary\n",
    "            ls = super().str_to_literal(text)\n",
    "            industry = []\n",
    "            for i in ls:\n",
    "                industry.append(i['category'])\n",
    "            return industry\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "careersfuture = CareersFuture(\"careersfuture\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = pd.DataFrame(careersfuture.clean_data())\n",
    "cf['Industry_unlisted'] = cf['Industry'].apply(lambda x: ','.join(map(str, x)))\n",
    "cf['Skills'] = cf['Skills'].apply(lambda x: x.replace(\"'\", \"\") )\n",
    "cf['Skills_unlisted'] = cf['Skills'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "cf_model = cf[[\"Job Title\", \"Job Description\", \"Industry_unlisted\", \"Skills_unlisted\", \"Job Experience Required (years)\",\"Job Monthly Min Sal\", \"Job Monthly Max Sal\" ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors = pd.read_csv(\"sfw_sector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('head of ', '')\n",
    "\n",
    "def clear_hierarchy(title):\n",
    "    split = title.split()\n",
    "    if (split[0] == 'assist') or (split[0]=='head'):\n",
    "        final_title = \" \".join(split[1:])\n",
    "    else:\n",
    "        final_title = title\n",
    "    return final_title\n",
    "\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].apply(lambda x: clear_hierarchy(x))\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('(specialist)', '')\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('specialist', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sf, X_test_sf, y_train_sf, y_test_sf = train_test_split(sf_sectors['Skill Title'], \n",
    "                                                    sf_sectors['Sector'], \n",
    "                                                    test_size = 0.03, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = sf_sectors['Sector'], \n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Pipeline([('vect', CountVectorizer(max_features = 5000, stop_words = 'english', min_df = 3, max_df = 0.5)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                                \n",
    "                ])\n",
    "X_train_dtm = transformer.fit_transform(sf_sectors['Skill Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10], 'gamma': [1,0.1,0.01, 0.001],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(SVC(class_weight='balanced', probability = True),param_grid,refit=True,verbose=2, n_jobs = -1, cv = 3)\n",
    "\n",
    "for train_indices, test_indices in k_fold.split(sf_sectors['Skill Title'], sf_sectors['Sector']):\n",
    "    X_train, X_test = X_train_dtm[train_indices], X_train_dtm[test_indices]\n",
    "    y_train, y_test = sf_sectors['Sector'][train_indices], sf_sectors['Sector'][test_indices]\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "# y_pred = logreg.predict(X_test_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C = 1, gamma = 1, kernel = 'linear', class_weight='balanced', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dtm, sf_sectors['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(transformer, open(\"tfidf.pickle\", \"wb\"))\n",
    "pickle.dump(model, open(\"model.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data, column):\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(len(data)):\n",
    "        data['Sector Label'] = le.fit_transform(data[column])\n",
    "        values = sf_sectors[['Sector Label', column]].drop_duplicates().sort_values('Sector Label').reset_index().drop(columns = 'index')\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"tfidf.pickle\", \"rb\"))\n",
    "model = pickle.load(open('industry.sav', 'rb'))\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_job_title(jd, vectorizer, model, data, nlp):\n",
    "    # replace skills here\n",
    "    transformed_jd = vectorizer.transform(pd.Series(jd))\n",
    "    probs = model.predict_proba(transformed_jd)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-3:]\n",
    "    labels = get_labels(data, 'Sector')\n",
    "    industries = labels.iloc[best_n[0]]['Sector'].to_list()\n",
    "    print(industries)\n",
    "    all_jobs = data[(data['Sector']== industries[0]) | (data['Sector']== industries[1]) | (data['Sector']== industries[2])]\n",
    "    \n",
    "    cf = nlp(str(jd))\n",
    "    print(\"User Input:\")\n",
    "    print(cf)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for j in range(0, len(all_jobs)):\n",
    "        sfw = nlp(str(all_jobs.iloc[j]['Skill Title']))\n",
    "        scores.append(sfw.similarity(cf))\n",
    "      \n",
    "        \n",
    "    ind1, ind2, ind3, ind4, ind5 = heapq.nlargest(5, zip(scores, all_jobs['Job_Role_Replaced']))\n",
    "    print(ind1)\n",
    "    print(ind2)\n",
    "    print(ind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[2000]['Skills_unlisted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[2000]['Job Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[2000]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp)\n",
    "#need to use skills \n",
    "#not the same sector but close job title from what it seems like based on jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[200]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Sector'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
