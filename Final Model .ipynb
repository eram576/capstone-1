{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import pickle\n",
    "import re\n",
    "import heapq\n",
    "import spacy\n",
    "\n",
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix,  classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Portal import *\n",
    "# pd.set_option('display.width', 400)\n",
    "# pd.set_option('display.max_columns', 10)\n",
    "\n",
    "\n",
    "class CareersFuture(Portal):\n",
    "\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def read_data(self):\n",
    "        # Reads data\n",
    "        df = pd.read_csv('mycareerfuture2020-09-15.csv', error_bad_lines=False)\n",
    "        return df\n",
    "\n",
    "    def clean_data(self):\n",
    "        df = self.read_data()\n",
    "        # df = df[df['Job Description'].str.contains('value')]\n",
    "        df['Job Description'] = df['Job Description'].astype(str)\n",
    "        df['Job Description'] = df['Job Description'].apply(lambda x: self.strip_html_tags(x))\n",
    "\n",
    "        df['Industry'] = df['Industry'].astype(str)\n",
    "        df['Industry'] = df['Industry'].apply(lambda x: self.str_to_literal(x))\n",
    "\n",
    "        # df['Skills'] = df['Skills'].astype(str)\n",
    "\n",
    "        df['Job Experience Required (years)'] = df['Job Experience Required (years)'].astype(int)\n",
    "\n",
    "        df['Job Monthly Min Sal'] = df['Job Monthly Min Sal'].astype(int)\n",
    "        df['Job Monthly Max Sal'] = df['Job Monthly Max Sal'].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def str_to_literal(self, text):\n",
    "        try:\n",
    "            # ast.literal_eval function converts takes in a string and converts it into a dictionary\n",
    "            ls = super().str_to_literal(text)\n",
    "            industry = []\n",
    "            for i in ls:\n",
    "                industry.append(i['category'])\n",
    "            return industry\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "careersfuture = CareersFuture(\"careersfuture\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = pd.DataFrame(careersfuture.clean_data())\n",
    "cf['Industry_unlisted'] = cf['Industry'].apply(lambda x: ','.join(map(str, x)))\n",
    "cf['Skills'] = cf['Skills'].apply(lambda x: x.replace(\"'\", \"\") )\n",
    "\n",
    "cf['Skills_unlisted'] = cf['Skills'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "cf['Skills_unlisted'] = cf[\"Skills_unlisted\"].apply(lambda a: a.lower())\n",
    "cf_model = cf[[\"Job Title\", \"Job Description\", \"Industry_unlisted\", \"Skills_unlisted\", \"Job Experience Required (years)\",\"Job Monthly Min Sal\", \"Job Monthly Max Sal\" ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cf_model[cf_model['Job Title'].str.contains('Cloud Operations Manage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors = pd.read_csv(\"sfw_sector.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Skill Title'] = sf_sectors[\"Skill Title\"].apply(lambda a: a.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(cf_model['Skills_unlisted'][0].split(\",\")).apply(lambda x: x.strip()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('head of ', '')\n",
    "\n",
    "def clear_hierarchy(title):\n",
    "    split = title.split()\n",
    "    if (split[0] == 'assist') or (split[0]=='head'):\n",
    "        final_title = \" \".join(split[1:])\n",
    "    else:\n",
    "        final_title = title\n",
    "    return final_title\n",
    "\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].apply(lambda x: clear_hierarchy(x))\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('(specialist)', '')\n",
    "sf_sectors['Job_Role_Replaced'] = sf_sectors['Job_Role_Replaced'].str.replace('specialist', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors = pd.read_csv('sf_model_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Skill Title'] = sf_sectors['Skill Title'].apply(lambda x: x.replace(\"'\", \"\"))\n",
    "sf_sectors['Skills_unlisted'] = sf_sectors['Skill Title'].apply(lambda x: x.replace('[','').replace(']','').replace(\",\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sf, X_test_sf, y_train_sf, y_test_sf = train_test_split(sf_sectors['Skill Title'], \n",
    "#                                                     sf_sectors['Sector'], \n",
    "#                                                     test_size = 0.03, \n",
    "#                                                     shuffle = True, \n",
    "#                                                     stratify = sf_sectors['Sector'], \n",
    "#                                                     random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer = Pipeline([('vect', CountVectorizer(max_features = 5000, stop_words = 'english', min_df = 3, max_df = 0.5)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                                \n",
    "                ])\n",
    "X_train_dtm = transformer.fit_transform(sf_sectors['Skills_unlisted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_fold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_grid = {'C': [0.1,1, 10], 'gamma': [1,0.1,0.01, 0.001],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GridSearchCV(SVC(class_weight='balanced', probability = True),param_grid,refit=True,verbose=2, n_jobs = -1, cv = 3)\n",
    "\n",
    "# for train_indices, test_indices in k_fold.split(sf_sectors['Skill Title'], sf_sectors['Sector']):\n",
    "#     X_train, X_test = X_train_dtm[train_indices], X_train_dtm[test_indices]\n",
    "#     y_train, y_test = sf_sectors['Sector'][train_indices], sf_sectors['Sector'][test_indices]\n",
    "#     model.fit(X_train, y_train)\n",
    "#     print(\"Best parameters set found on development set:\")\n",
    "#     print()\n",
    "#     print(model.best_params_)\n",
    "#     print()\n",
    "\n",
    "#     y_true, y_pred = y_test, model.predict(X_test)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print()\n",
    "\n",
    "\n",
    "\n",
    "# # y_pred = logreg.predict(X_test_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C = 1, gamma = 1, kernel = 'linear', class_weight='balanced', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_dtm, sf_sectors['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(transformer, open(\"tfidf.pickle\", \"wb\"))\n",
    "pickle.dump(model, open(\"model.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load(open(\"tfidf.pickle\", \"rb\"))\n",
    "model = pickle.load(open('model.sav', 'rb'))\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data, column):\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for i in range(len(data)):\n",
    "        data['Sector Label'] = le.fit_transform(data[column])\n",
    "        values = sf_sectors[['Sector Label', column]].drop_duplicates().sort_values('Sector Label').reset_index().drop(columns = 'index')\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mydict = np.load('skills_dict.npy',allow_pickle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_list(role):\n",
    "    \n",
    "    return role.replace(\"['\",'').replace(\"']\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_job_portal_skills(skills_list, mydict):\n",
    "    new_list = []\n",
    "    for i in range(0, len(skills_list)):\n",
    "        if skills_list[i] in mydict.item().keys():\n",
    "            new_list.append(mydict.item().get(skills_list[i]))\n",
    "        else:\n",
    "            new_list.append(skills_list[i])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_job_title(skills, vectorizer, model, data, nlp, mydict):\n",
    "\n",
    "    skills_list = pd.Series(skills[0].split(\",\")).apply(lambda x: x.strip()).tolist() # list sfw skills\n",
    "    skills_listed = replace_job_portal_skills(skills_list, mydict) # replaces and returns a list\n",
    "    skills = \" \".join(skills_listed)\n",
    "    \n",
    "    transformed_skills = vectorizer.transform(pd.Series(skills)) # unlist sfw skills\n",
    "    probs = model.predict_proba(transformed_skills)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-4:]\n",
    "    labels = get_labels(data, 'Sector')\n",
    "    industries = labels.iloc[best_n[0]]['Sector'].to_list()\n",
    "    #print(industries)\n",
    "    all_jobs = data[(data['Sector']== industries[0]) | (data['Sector']== industries[1]) | (data['Sector']== industries[2]) | (data['Sector']== industries[3])]\n",
    "    \n",
    "    cf = nlp(str(skills))\n",
    "    #print(\"User Input (job portal skills):\")\n",
    "    #print(cf)\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    \n",
    "    for j in range(0, len(all_jobs)):\n",
    "        sfw = nlp(str(all_jobs.iloc[j]['Skill Title']))\n",
    "        scores.append(sfw.similarity(cf))\n",
    "      \n",
    "        \n",
    "    ind1, ind2, ind3, ind4, ind5 = heapq.nlargest(5, zip(scores, all_jobs['Job Role']))\n",
    "    \n",
    "#     print(ind1[0])\n",
    "#     print(type(ind1[0]))\n",
    "    if ((ind1[0]<= 0.5) | (ind2[0]<= 0.5) | (ind3[0]<= 0.5)):\n",
    "        print('Warning: Not a close match')\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"SFW Job Role: \", clear_list(ind1[1]), \"Score: \", ind1[0])\n",
    "    print(\"SFW Job Role: \", clear_list(ind2[1]), \"Score: \", ind2[0])\n",
    "    print(\"SFW Job Role: \", clear_list(ind3[1]), \"Score: \", ind3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[0]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[584]['Skills_unlisted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[584]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#industry\n",
    "retrieve_job_title(pd.Series(cf_model.iloc[2000]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp)\n",
    "#need to use skills \n",
    "#not the same sector but close job title from what it seems like based on jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "retrieve_job_title(pd.Series(cf_model.iloc[2000]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)\n",
    "#need to use skills \n",
    "#not the same sector but close job title from what it seems like based on jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cf_model.iloc[901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#industry\n",
    "retrieve_job_title(pd.Series(cf_model.iloc[901]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)\n",
    "#need to use skills \n",
    "#not the same sector but close job title from what it seems like based on jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cf_model.iloc[702]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[702]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)\n",
    "#need to use skills \n",
    "#not the same sector but close job title from what it seems like based on jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_model.iloc[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_job_title(pd.Series(cf_model.iloc[200]['Skills_unlisted']), vectorizer, model, sf_sectors, nlp, mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_sectors['Sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_1_sfw_jobs = []\n",
    "closest_1_sfw_skills = []\n",
    "closest_1_scores = []\n",
    "\n",
    "closest_2_sfw_jobs = []\n",
    "closest_2_sfw_skills = []\n",
    "closest_2_scores = []\n",
    "\n",
    "closest_2_sfw_jobs = []\n",
    "closest_2_sfw_skills = []\n",
    "closest_2_scores = []\n",
    "\n",
    "job_portal_job = []\n",
    "\n",
    "for i in range(0, len(cf_model)):\n",
    "    skills = cf_model['Skills_unlisted'][i]\n",
    "    data = sf_sector\n",
    "    top_1_job, top_1_skills, top_1_score, top_2_job, top_2_skills, top_2_score, top_3_job, top_3_skills, top_3_score = retrieve_job_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_job_title(skills, vectorizer, model, data, nlp, mydict):\n",
    "\n",
    "    skills_list = pd.Series(skills[0].split(\",\")).apply(lambda x: x.strip()).tolist() # list of skills\n",
    "    skills_listed = replace_job_portal_skills(skills_list, mydict) #replaces and returns a list\n",
    "    skills = \" \".join(skills_listed) #unlistes skills\n",
    "    \n",
    "    transformed_skills = vectorizer.transform(pd.Series(skills)) \n",
    "    probs = model.predict_proba(transformed_skills)\n",
    "    best_n = np.argsort(probs, axis=1)[:,-3:]\n",
    "    labels = get_labels(data, 'Sector')\n",
    "    industries = labels.iloc[best_n[0]]['Sector'].to_list()\n",
    "    print(industries)\n",
    "    all_jobs = data[(data['Sector']== industries[0]) | (data['Sector']== industries[1]) | (data['Sector']== industries[2])]\n",
    "    \n",
    "    cf = nlp(str(skills))\n",
    "    print(\"User Input (job portal skills):\")\n",
    "    print(cf)\n",
    "\n",
    "    scores = []\n",
    "    for j in range(0, len(all_jobs)):\n",
    "        sfw = nlp(str(all_jobs.iloc[j]['Skill Title']))\n",
    "        scores.append(sfw.similarity(cf))\n",
    "      \n",
    "        \n",
    "    ind1, ind2, ind3, ind4, ind5 = heapq.nlargest(5, range(len(scores)))\n",
    "    \n",
    "    top_1_job = all_jobs.iloc[ind1]['job_role_replaced'] # return actual sfw job\n",
    "    top_1_skills = all_jobs.iloc[ind1]['Skill Title']  # create a comma separated col of skills in sfw data\n",
    "    top_1_score = scores[ind1]\n",
    "    \n",
    "    top_2_job = all_jobs.iloc[ind2]['job_role_replaced']\n",
    "    top_2_skills = all_jobs.iloc[ind2]['Skill Title']\n",
    "    top_2_score = scores[ind2]\n",
    "    \n",
    "    top_3_job = all_jobs.iloc[ind3]['job_role_replaced']\n",
    "    top_3_skills = all_jobs.iloc[ind3]['Skill Title']\n",
    "    top_3_score = scores[ind3]\n",
    "    \n",
    "    return top_1_job, top_1_skills, top_1_score, top_2_job, top_2_skills, top_2_score, top_3_job, top_3_skills, top_3_score\n",
    "                                                  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
